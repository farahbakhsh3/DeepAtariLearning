{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farahbakhsh3/DeepAtariLearning/blob/master/new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L5w19DhuOvoc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/nxz7aqtmsiusezd/atari.rar\n",
        "!apt install unrar\n",
        "!unrar x -r atari.rar\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I04o0pwCPFZM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, ConvLSTM2D, MaxPool2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from prepare import Sample, model_def\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def create_model_ConvLSTM2D(INPUT_SHAPE, OUT_SHAPE, dropout_prob=0.5):\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(ConvLSTM2D(32, kernel_size=(3, 3), padding='same', \n",
        "                            activation='relu', return_sequences=True, strides=(2, 2),\n",
        "                            recurrent_dropout=dropout_prob//2, dropout=dropout_prob,\n",
        "                            input_shape=INPUT_SHAPE))\n",
        "#     model.add(ConvLSTM2D(32, kernel_size=(3, 3), padding='same', \n",
        "#                             activation='relu', return_sequences=True, strides=(2, 2)))\n",
        "#     model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "#     model.add(Dropout(dropout_prob))\n",
        "\n",
        "    model.add(ConvLSTM2D(64, kernel_size=(3, 3), padding='same', \n",
        "                            activation='relu', return_sequences=True,\n",
        "                            recurrent_dropout=dropout_prob//2, dropout=dropout_prob))\n",
        "    model.add(ConvLSTM2D(64, kernel_size=(3, 3), padding='same', \n",
        "                            activation='relu', return_sequences=True, strides=(2, 2),\n",
        "                            recurrent_dropout=dropout_prob//2, dropout=dropout_prob))\n",
        "#     model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "#     model.add(Dropout(dropout_prob))\n",
        "\n",
        "#     model.add(ConvLSTM2D(128, kernel_size=(3, 3), padding='same',  \n",
        "#                             activation='relu', return_sequences=True))\n",
        "    model.add(ConvLSTM2D(128, kernel_size=(3, 3), padding='same', \n",
        "                            activation='relu', strides=(2, 2),\n",
        "                            recurrent_dropout=dropout_prob//2, dropout=dropout_prob))\n",
        "#     model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "#     model.add(Dropout(dropout_prob))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(dropout_prob))\n",
        "    model.add(Dense(OUT_SHAPE, activation='softmax'))\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_Conv2D(INPUT_SHAPE, OUT_SHAPE, dropout_prob=0.5):\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', \n",
        "                        activation='relu', input_shape=INPUT_SHAPE))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', \n",
        "                        activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout_prob))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', \n",
        "                        activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', \n",
        "                        activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout_prob))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', \n",
        "                        activation='relu'))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', \n",
        "                        activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout_prob))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(dropout_prob))\n",
        "    model.add(Dense(OUT_SHAPE, activation='softmax'))\n",
        "    print(model.summary())\n",
        "    \n",
        "    return model\n",
        "\n",
        "def train_generator(x_train, y_train, batch_size):\n",
        "    index = _model_def.window_size\n",
        "    while True:\n",
        "        x = []\n",
        "        y = []\n",
        "        for i in range(batch_size):\n",
        "            x.append(x_train[index - _model_def.window_size + i:index + i])\n",
        "            y.append(y_train[index + i - 1])\n",
        "\n",
        "        x = np.array(x)\n",
        "        y = np.array(y)\n",
        "        index += batch_size\n",
        "        if index >= x_train.shape[0] - batch_size:\n",
        "            index = _model_def.window_size\n",
        "\n",
        "        yield x, y\n",
        "\n",
        "def validation_generator(x_val, y_val, batch_size):\n",
        "    index = _model_def.window_size\n",
        "    while True:\n",
        "        x = []\n",
        "        y = []\n",
        "        for i in range(batch_size):\n",
        "            x.append(x_val[index - _model_def.window_size + i:index + i])\n",
        "            y.append(y_val[index + i - 1])\n",
        "\n",
        "        x = np.array(x)\n",
        "        y = np.array(y)\n",
        "        index += batch_size\n",
        "        if index >= x_val.shape[0] - batch_size:\n",
        "            index = _model_def.window_size\n",
        "\n",
        "        yield x, y\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    _model_def = model_def()\n",
        "    x_data = np.load(\"X.npy\")\n",
        "    y_data = np.load(\"Y.npy\")\n",
        "    y_data = to_categorical(y_data, num_classes=_model_def.OUT_SHAPE)\n",
        "\n",
        "    h = int(x_data.shape[0] * 0.9)\n",
        "    x_train = x_data[:h]\n",
        "    y_train = y_data[:h]\n",
        "    x_val = x_data[h:]\n",
        "    y_val = y_data[h:]\n",
        "\n",
        "    epochs = 50\n",
        "    batch_size = 32\n",
        "    _model_def.window_size = 10\n",
        "\n",
        "    if _model_def.model == 'Conv2D':\n",
        "        model = create_model_Conv2D(_model_def.INPUT_SHAPE, _model_def.OUT_SHAPE)\n",
        "    elif _model_def.model == 'ConvLSTM2D':\n",
        "        model = create_model_ConvLSTM2D(_model_def.INPUT_SHAPE, _model_def.OUT_SHAPE)\n",
        "\n",
        "    print('---------------------------')\n",
        "    print('X_Train Shape: ', x_train.shape)\n",
        "    print('Y_Train Shape: ', y_train.shape)\n",
        "    print('---------------------------')\n",
        "    print('X_Validation Shape: ', x_val.shape)\n",
        "    print('Y_Validation Shape: ', y_val.shape)\n",
        "    print('---------------------------')\n",
        "    \n",
        "    if input('Train from zero: <z>  ,  Retrain by load prev weights: <r>  ::   ') == 'r':\n",
        "        model.load_weights(_model_def.weights_file)\n",
        "        print('Model weights loaded : ', _model_def.weights_file) \n",
        "    else:\n",
        "        print('Train from zero.')\n",
        "    print('---------------------------')\n",
        "    \n",
        "    chekpoint = ModelCheckpoint(filepath=_model_def.weights_file, \n",
        "                                monitor='val_acc', \n",
        "                                save_best_only=True, \n",
        "                                save_weights_only=True, \n",
        "                                verbose=True)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                    optimizer='adam', \n",
        "                    metrics=['accuracy'])\n",
        "    \n",
        "    if _model_def.model == 'Conv2D':\n",
        "        history = model.fit(x_train, y_train, \n",
        "                            batch_size=batch_size, \n",
        "                            epochs=epochs, \n",
        "                            validation_split=0.05, \n",
        "                            callbacks=[chekpoint])\n",
        "\n",
        "    elif _model_def.model == 'ConvLSTM2D':\n",
        "        history = model.fit_generator(train_generator(x_train, y_train, batch_size), \n",
        "                            steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                            epochs=epochs, \n",
        "                            validation_data=validation_generator(x_val, y_val, batch_size), \n",
        "                            validation_steps=x_val.shape[0]//batch_size,\n",
        "                            callbacks=[chekpoint])\n",
        "\n",
        "    history_dict = history.history\n",
        "    acc_value = history_dict['acc']\n",
        "    loss_value = history_dict['loss']\n",
        "    val_acc_value = history_dict['val_acc']\n",
        "    val_loss_value = history_dict['val_loss']\n",
        "    epoches = range(1,len(acc_value) + 1)\n",
        "\n",
        "    plt.plot(epoches, val_acc_value, 'r', label='Validation accuracy')\n",
        "    plt.plot(epoches, acc_value, 'b', label='Train accuracy')\n",
        "    plt.title('accuracy')\n",
        "    plt.xlabel('Epoches')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epoches, val_loss_value, 'r', label='Valdation loss')\n",
        "    plt.plot(epoches, loss_value, 'b', label='Train loss')\n",
        "    plt.title('loss')\n",
        "    plt.xlabel('Epoches')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print('Best weights saved. ', _model_def.weights_file)\n",
        "    print('---------------------------')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NlYQjq8RvdKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install dropbox\n",
        "\n",
        "import dropbox\n",
        "from dropbox.files import WriteMode\n",
        " \n",
        "filepath = 'ConvLSTM2D_Riverraid.h5'\n",
        "access_token = 'PqHDQ2OWJuYAAAAAAAAAWLZTlsb3kgWEhjrKQLeztfPalb3D9eJDueslYKgMNW7d'\n",
        "dbx = dropbox.Dropbox(access_token)\n",
        "f = open(filepath, 'rb')\n",
        "_File = '/' + filepath\n",
        "dbx.files_upload(f.read(), _File, mode=WriteMode('overwrite', None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IM1XCnNG_K4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}